from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

# === ×©×œ×‘ 1: ×¤×ª×™×—×ª Spark Session ===
spark = SparkSession.builder \
    .appName("BookRecommenderALS") \
    .config("spark.driver.extraClassPath", "sqlite-jdbc-3.41.2.1.jar") \
    .getOrCreate()

print("âœ… Spark Session started")

# === ×©×œ×‘ 2: ×˜×¢×™× ×ª ×”×˜×‘×œ××•×ª ××”-DB ===
db_path = "books.db"

ratings = spark.read.format("jdbc") \
    .option("url", f"jdbc:sqlite:{db_path}") \
    .option("dbtable", "books_ratings") \
    .load()

books = spark.read.format("jdbc") \
    .option("url", f"jdbc:sqlite:{db_path}") \
    .option("dbtable", "books") \
    .load()

# === ×©×œ×‘ 3: ×¢×™×‘×•×“ ×”×“××˜×” ×œ-ALS ===
ratings_df = ratings.select(
    col("user_id").cast("int"),
    col("book_id").cast("int"),
    col("rating").cast("float")
).na.drop()

# === ×©×œ×‘ 4: ×‘× ×™×™×ª ALS ===
als = ALS(
    userCol="user_id",
    itemCol="book_id",
    ratingCol="rating",
    coldStartStrategy="drop"
)

# === ×©×œ×‘ 5: ×‘× ×™×™×ª Grid ×©×œ ×¤×¨××˜×¨×™× ×œ-CV ===
paramGrid = ParamGridBuilder() \
    .addGrid(als.rank, [5, 10, 15]) \
    .addGrid(als.maxIter, [5, 10]) \
    .addGrid(als.regParam, [0.05, 0.1]) \
    .build()

evaluator = RegressionEvaluator(
    metricName="rmse",
    labelCol="rating",
    predictionCol="prediction"
)

# === ×©×œ×‘ 6: Cross Validation ×¢× 10 folds ===
cv = CrossValidator(
    estimator=als,
    estimatorParamMaps=paramGrid,
    evaluator=evaluator,
    numFolds=10,
    parallelism=2  # ×œ×”×¨×™×¥ ×‘××§×‘×™×œ ×× ×™×© ×œ×™×‘×” ×¤× ×•×™×”
)

# === ×©×œ×‘ 7: ××™××•×Ÿ ===
print("ğŸš€ Training ALS model with 10-fold CV...")
cvModel = cv.fit(ratings_df)

# === ×©×œ×‘ 8: ×‘×“×™×§×” ×¢×œ ×›×œ ×”×“××˜×” (×¨×§ ×›×“×™ ×œ××“×•×“ RMSE) ===
predictions = cvModel.transform(ratings_df)
rmse = evaluator.evaluate(predictions)
print(f"âœ… Best Model RMSE = {rmse}")

# === ×©×œ×‘ 9: ×”×¤×§×ª ×”××œ×¦×•×ª ×œ××©×ª××© ××¡×•×™× ===
bestModel = cvModel.bestModel
user_id = 60244  # ××¤×©×¨ ×œ×©× ×•×ª ×œ××©×ª××© ×©××ª ×¨×•×¦×”
userRecs = bestModel.recommendForAllUsers(5)
userRecs.filter(col("user_id") == user_id).show(truncate=False)

# === ×©×œ×‘ 10: ×”×¦×’×ª ×©××•×ª ×”×¡×¤×¨×™× ×”××•××œ×¦×™× ===
from pyspark.sql.functions import explode

recs = userRecs.filter(col("user_id") == user_id) \
    .select("user_id", explode("recommendations").alias("rec")) \
    .select("user_id", col("rec.book_id").alias("book_id"), col("rec.rating").alias("predicted_rating"))

recs = recs.join(books, on="book_id", how="left")
recs.show(truncate=False)

input("Press Enter to stop Spark...")
spark.stop()

